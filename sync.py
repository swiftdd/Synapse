# -*- coding: utf-8 -*-
import os, requests, re, shutil
from collections import defaultdict

# --- ç³»ç»Ÿé…ç½®åŒº ---
TOKEN = os.environ.get('G_T')
OWNER = "swiftdd"
NAME = "Synapse"  # ç¡®ä¿ä¸ä½ åˆ›å»ºçš„ä»“åº“åä¸€è‡´
# ------------------

def get_discussions():
    url = "https://api.github.com/graphql"
    headers = {"Authorization": f"Bearer {TOKEN}"}
    # GraphQL æŸ¥è¯¢ï¼šåªæŠ“å–æœ€æ–°ç”Ÿæˆçš„è®¨è®º
    query = """
    query($owner: String!, $name: String!) {
      repository(owner: $owner, name: $name) {
        discussions(first: 100, orderBy: {field: CREATED_AT, direction: DESC}) {
          nodes {
            title, url, body, createdAt
            category { name }
          }
        }
      }
    }
    """
    try:
        vars = {"owner": OWNER, "name": NAME}
        resp = requests.post(url, json={"query": query, "variables": vars}, headers=headers).json()
        if 'errors' in resp:
            print(f"GraphQL Errors: {resp['errors']}")
            return []
        return resp['data']['repository']['discussions']['nodes']
    except Exception as e:
        print(f"Connection failed: {e}")
        return []

def sync():
    # 1. ç¯å¢ƒåˆå§‹åŒ–
    for d in ["BACKUP", "wiki_temp"]:
        if os.path.exists(d): shutil.rmtree(d)
        os.makedirs(d)

    data = get_discussions()
    categories = defaultdict(list)

    # 2. è½¬æ¢è®¨è®ºæµä¸ºç‰©ç†èŠ‚ç‚¹
    for item in data:
        title, body, cat = item['title'], item['body'], item['category']['name']
        date = item['createdAt'].split('T')[0]
        clean_t = re.sub(r'[\/\\:\*\?"<>\|]', '', title).strip().replace(" ", "-")
        
        # A. ç‰©ç†å¤‡ä»½ (BACKUP/åˆ†ç±»/æ—¥æœŸ-æ ‡é¢˜.md)
        cat_path = os.path.join("BACKUP", cat)
        if not os.path.exists(cat_path): os.makedirs(cat_path)
        f_name = f"{date}-{clean_t}.md"
        with open(os.path.join(cat_path, f_name), "w", encoding="utf-8") as f:
            f.write(f"# {title}\n\n> System-Link: {item['url']}\n\n{body or ''}")

        # B. Wiki ç¼“å­˜
        w_name = f"[{cat}] {date}-{clean_t}.md"
        with open(os.path.join("wiki_temp", w_name), "w", encoding="utf-8") as f:
            f.write(f"# {title}\n\n> **Category**: {cat} | **Date**: {date}\n\n---\n\n{body or ''}")

        # C. åˆ†ç±»ç»Ÿè®¡
        rel_p = f"BACKUP/{cat}/{f_name}".replace(" ", "%20")
        categories[cat].append(f"- [{title}]({rel_p}) â€” `{date}`")

    # 3. æ„å»º README ç§‘æŠ€æ„Ÿä»ªè¡¨ç›˜
    content = f"# ğŸŒ {NAME} / Thought Protocol\n\n"
    content += f"> **Status**: Online | **Identity**: {OWNER}\n\n"
    content += f"[[ ğŸ§  Wiki-Cortex ]](https://github.com/{OWNER}/{NAME}/wiki) | [[ ğŸ’¬ Input-Stream ]](https://github.com/{OWNER}/{NAME}/discussions)\n\n---\n"
    
    if not categories:
        content += "\n> [!CAUTION]\n> NO NEURAL NODES DETECTED. INITIALIZE VIA DISCUSSIONS.\n"
    else:
        for cat_name in sorted(categories.keys()):
            posts = categories[cat_name]
            content += f"### ğŸ“‚ SECTION_{cat_name.upper()} ({len(posts)})\n"
            content += "\n".join(posts[:5]) + "\n"
            if len(posts) > 5:
                content += f"\n<details>\n<summary>â–¶ EXPAND_DATA_STREAM ({len(posts)-5} MORE)</summary>\n\n" + "\n".join(posts[5:]) + "\n\n</details>\n"
            content += "\n"

    # 4. ç”Ÿæˆæ–‡ä»¶
    with open("README.md", "w", encoding="utf-8") as f: f.write(content)
    with open("index.md", "w", encoding="utf-8") as f: f.write("---\nlayout: default\n---\n\n" + content)
    open(".nojekyll", "w").close()
    
    print(f"Synced {len(data)} nodes.")

if __name__ == "__main__":
    sync()
